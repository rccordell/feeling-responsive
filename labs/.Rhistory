spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
View(books_words)
books_sentiment <- books_words %>%
inner_join(bing) %>%
count(title, author, index = as.numeric(rownames(.)) %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
rm(bing)
?line_number
??line_number
?sort
booklist <- gutenberg_works(gutenberg_bookshelf == "Science Fiction", languages = "en", only_text = TRUE)
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
select(text, title, author) %>%
filter(text != "") %>%
na.omit() %>%
sort(length(text))
?length
View(booklist)
length(booklist$title)
length("happy")
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
select(text, title, author) %>%
filter(text != "") %>%
na.omit() %>%
sort(nchar(text))
nchar(booklist$title)
sort(nchar(booklist$title))
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
select(text, title, author) %>%
filter(text != "") %>%
na.omit() %>%
sort(nchar(.$text))
?order
?sort
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
mutate(text_length) %>%
sort(desc(text_length)) %>%
select(text, title, author) %>%
filter(text != "") %>%
na.omit()
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
mutate(text_length = length(text)) %>%
sort(desc(text_length)) %>%
select(text, title, author) %>%
filter(text != "") %>%
na.omit()
?length
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
mutate(characters = nchar(text)) %>%
sort(desc(characters)) %>%
select(text, title, author) %>%
filter(text != "") %>%
na.omit()
books <- read.csv("data/scifi.csv", stringsAsFactors=FALSE) %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " "))
rm(booklist)
View(books)
booklist <- gutenberg_works(gutenberg_bookshelf == "Science Fiction", languages = "en", only_text = TRUE)
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) %>%
sort(desc(characters)) %>%
select(text, title, author) %>%
filter(text != "") %>%
na.omit()
View(books)
nchar(books$text)
books <- read.csv("data/scifi.csv", stringsAsFactors=FALSE, encoding="UTF-8") %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " "))
nchar(books$text)
books <- read.csv("data/scifi.csv", stringsAsFactors=FALSE, encoding="latin1") %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " "))
nchar(books$text)
books <- read.csv("data/scifi.csv", stringsAsFactors=FALSE, encoding="latin1") %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) %>%
sort(desc(characters))
books <- read.csv("data/scifi.csv", stringsAsFactors=FALSE, encoding="latin1") %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) # %>%
View(books)
books <- books %>% sort(desc(characters))
?sort
?order
??dplyr
?arrange
books <- read.csv("data/scifi.csv", stringsAsFactors=FALSE, encoding="latin1") %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) %>%
arrange(desc(characters))
View(books)
?slice
slice(books, 1:50)
books <- slice(books, 1:100)
books <- read.csv("data/scifi.csv", stringsAsFactors=FALSE, encoding="latin1") %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) %>%
arrange(desc(characters)) %>%
slice(1:100)
books  %>%
ungroup() %>%
slice(1:100)
books <- books %>%
ungroup() %>%
slice(1:100)
View(books)
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) %>%
sort(desc(characters)) %>%
select(text, title, author) %>%
filter(text != "") %>%
na.omit()
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) %>%
arrange(desc(characters)) %>%
ungroup() %>%
slice(1:100) %>%
select(text, title, author)
?gutenberg_download
write.csv(books, file = "data/scifi.csv")
rm(booklist)
books <- read.csv("data/scifi.csv", stringsAsFactors=FALSE, encoding="latin1")
View(books)
books <- read.csv("data/scifi.csv", stringsAsFactors=FALSE, encoding="latin1") %>%
select(text, title, author)
books_words <- books %>%
unnest_tokens(word, text)
sentiments <- get_sentiments("nrc")  %>% filter(sentiment == "anger")
View(sentiments)
books_words %>%
semi_join(sentiments) %>%
count(word, sort = TRUE)
books_words %>%
filter(word %in% sentiments$word) %>%
count(title, author, sort=TRUE) %>%
View()
angry_books <- books_words %>%
filter(word %in% sentiments$word) %>%
count(title, author, sort=TRUE) %>%
slice(1:9)
books_sentiment <- books_words %>%
inner_join(get_sentiments("bing")) %>%
count(title, author, index = as.numeric(rownames(.)) %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(books_sentiment %>% filter(title %in% angry_books$title),
aes(index, sentiment, fill = title)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~title, ncol = 3, scales = "free_x")
books_chapters <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %>%
ungroup() %>%
filter(chapter > 0) %>%
group_by(title, chapter) %>%
summarise(text = paste(text, collapse=" ")) %>%
unite(book_chapter, title, chapter)
mallet.instances <- mallet.import(id.array = as.character(books_chapters$book_chapter),
text.array = as.character(books_chapters$text),
stoplist.file = "data/stopwords.txt")
n.topics <- 20
topic.model <- MalletLDA(num.topics=n.topics, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(mallet.instances)
topic.model$setAlphaOptimization(20, 50)
topic.model$train(500)
topic.model$maximize(10)
# What are the top 10 words in topic 2?
topic.words <- mallet.topic.words(topic.model)
mallet.top.words(topic.model, word.weights = topic.words[2,], num.top.words = 10)
View(books_chapters)
View(books)
View(books)
books <- read.csv("data/scifi.csv", stringsAsFactors=FALSE, encoding="latin1") %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) %>%
arrange(desc(characters)) %>%
ungroup() %>%
slice(1:100)
View(books)
View(books)
write.csv(books, file = "data/scifi.csv")
View(books)
books <- read.csv("data/scifi.csv", stringsAsFactors=FALSE, encoding="latin1") %>%
select(text, title, author)
View(books)
books_words <- books %>%
unnest_tokens(word, text)
angry_books <- books_words %>%
filter(word %in% sentiments$word) %>%
count(title, author, sort=TRUE) %>%
slice(1:9)
books_sentiment <- books_words %>%
inner_join(get_sentiments("bing")) %>%
count(title, author, index = as.numeric(rownames(.)) %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(books_sentiment %>% filter(title %in% angry_books$title),
aes(index, sentiment, fill = title)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~title, ncol = 3, scales = "free_x")
books_chapters <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %>%
ungroup() %>%
filter(chapter > 0) %>%
group_by(title, chapter) %>%
summarise(text = paste(text, collapse=" ")) %>%
unite(book_chapter, title, chapter)
books$text[,1]
books$text[1,]
books$text
mallet.instances <- mallet.import(id.array = as.character(nrow(books)),
text.array = as.character(books$text),
stoplist.file = "data/stopwords.txt")
mallet.instances <- mallet.import(id.array = as.character(books$title),
text.array = as.character(books$text),
stoplist.file = "data/stopwords.txt")
n.topics <- 20
topic.model <- MalletLDA(num.topics=n.topics, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(mallet.instances)
topic.model$setAlphaOptimization(20, 50)
topic.model$train(500)
topic.model$maximize(10)
rm(books_chapters)
# What are the top 10 words in topic 2?
topic.words <- mallet.topic.words(topic.model)
mallet.top.words(topic.model, word.weights = topic.words[2,], num.top.words = 10)
topic_labels <- rep("", n.topics)
for (topic in 1:n.topics) {
topic_labels[topic] <- paste(
mallet.top.words(topic.model, topic.words[topic,], num.top.words=5)$words, collapse=" "
)}
vocabulary <- topic.model$getVocabulary()
word_freqs <- mallet.word.freqs(topic.model)
wordFrame <- topic.words %>% as_data_frame()
colnames(wordFrame) <- vocabulary
rownames(wordFrame) <- topic_labels
wordFrame <- wordFrame %>% rownames_to_column("tmodel")
View(wordFrame)
gatherWords <- wordFrame %>% gather(word, count, -tmodel) %>% filter(count!=0)
word2search <- "nice"
gatherWords %>% filter(word == word2search) %>%
ggplot() +
geom_bar(stat = "identity", aes(x=reorder(tmodel, count),y=count, fill=tmodel)) +
coord_flip() +
labs(x="Topic",y="Proportion") +
ggtitle(paste("Weight of the word", word2search, "in topics")) +
theme(plot.title = element_text(family = "Trebuchet MS", color="#666666", face="bold", size=22, hjust=0.5))
word2search <- "rocket"
gatherWords %>% filter(word == word2search) %>%
ggplot() +
geom_bar(stat = "identity", aes(x=reorder(tmodel, count),y=count, fill=tmodel)) +
coord_flip() +
labs(x="Topic",y="Proportion") +
ggtitle(paste("Weight of the word", word2search, "in topics")) +
theme(plot.title = element_text(family = "Trebuchet MS", color="#666666", face="bold", size=22, hjust=0.5))
#Gets a list of the documents and topics
doc.topics <- mallet.doc.topics(topic.model, smoothed=T, normalized=T)
rownames(doc.topics) = austen_chunks$book
colnames(doc.topics) = topic_labels
rownames(doc.topics) = books$title
colnames(doc.topics) = topic_labels
topicDF <- doc.topics %>%
as_data_frame() %>%
mutate(title = rownames(doc.topics)) %>%
gather(topic, proportion, -title)
View(topicDF)
# we could also arrange our table by title
topicDF %>%
arrange(title) %>%
View()
p <- topicDF %>%
group_by(topic) %>%
mutate(id = 1:n()) %>%
ggplot() +
geom_tile(aes(x=id,y=topic,fill=proportion,text = paste("title:", title)))
ggplotly(p)
library(plotly)
ggplotly(p)
t <- ggplot(topicDF %>%
separate(title, c("title","chunk"), sep="-")) +
geom_point(aes(x=topic,y=proportion,text = paste("title:", title))) +
coord_flip() +
facet_grid(. ~ title)
ggplotly(t)
t <- ggplot(topicDF %>%
t <- ggplot(topicDF) +
geom_point(aes(x=topic,y=proportion,text = paste("title:", title))) +
coord_flip() +
facet_grid(. ~ title)
ggplotly(t)
t <- ggplot(topicDF) +
geom_point(aes(x=topic,y=proportion,text = paste("title:", title))) +
coord_flip() +
facet_grid(. ~ title)
ggplotly(t)
rm(t)
ggplotly(p)
library(data.table)
booklist <- gutenberg_works(gutenberg_bookshelf == "Science Fiction", languages = "en", only_text = TRUE)
books <- gutenberg_download(c(booklist$gutenberg_id), meta_fields = c("title","author"), strip = TRUE) %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
ungroup() %>%
select(text, title, author)
write.csv(books, file = "data/scifi.csv")
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="latin1") %>%
select(text, title, author)
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
select(text, title, author)
View(books)
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) %>%
arrange(desc(characters)) %>%
ungroup() %>%
slice(1:500) %>%
select(text, title, author)
write.csv(books, file = "data/scifi.csv")
books <- slice(books, 1:250)
write.csv(books, file = "data/scifi.csv")
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
select(text, title, author)
books_words <- books %>%
unnest_tokens(word, text)
sentiments <- get_sentiments("nrc") # %>% filter(sentiment == "anger")
View(sentiments)
sentiments <- get_sentiments("nrc")  %>% filter(sentiment == "anger")
angry_books <- books_words %>%
filter(word %in% sentiments$word) %>%
count(title, author, sort=TRUE) %>%
slice(1:9)
books_sentiment <- books_words %>%
inner_join(get_sentiments("bing")) %>%
count(title, author, index = as.numeric(rownames(.)) %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
ggplot(books_sentiment %>% filter(title %in% angry_books$title),
aes(index, sentiment, fill = title)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~title, ncol = 3, scales = "free_x")
mallet.instances <- mallet.import(id.array = as.character(books$title),
text.array = as.character(books$text),
stoplist.file = "data/stopwords.txt")
n.topics <- 20
topic.model <- MalletLDA(num.topics=n.topics, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(mallet.instances)
topic.model$setAlphaOptimization(20, 50)
topic.model$train(500)
topic.model$maximize(10)
# What are the top 10 words in topic 2?
topic.words <- mallet.topic.words(topic.model)
mallet.top.words(topic.model, word.weights = topic.words[2,], num.top.words = 10)
topic_labels <- rep("", n.topics)
for (topic in 1:n.topics) {
topic_labels[topic] <- paste(
mallet.top.words(topic.model, topic.words[topic,], num.top.words=5)$words, collapse=" "
)}
vocabulary <- topic.model$getVocabulary()
word_freqs <- mallet.word.freqs(topic.model)
wordFrame <- topic.words %>% as_data_frame()
colnames(wordFrame) <- vocabulary
rownames(wordFrame) <- topic_labels
wordFrame <- wordFrame %>% rownames_to_column("tmodel")
gatherWords <- wordFrame %>% gather(word, count, -tmodel) %>% filter(count!=0)
word2search <- "rocket"
gatherWords %>% filter(word == word2search) %>%
ggplot() +
geom_bar(stat = "identity", aes(x=reorder(tmodel, count),y=count, fill=tmodel)) +
coord_flip() +
labs(x="Topic",y="Proportion") +
ggtitle(paste("Weight of the word", word2search, "in topics")) +
theme(plot.title = element_text(family = "Trebuchet MS", color="#666666", face="bold", size=22, hjust=0.5))
books <- books %>% slice(1:500)
mallet.instances <- mallet.import(id.array = as.character(books$title),
text.array = as.character(books$text),
stoplist.file = "data/stopwords.txt")
n.topics <- 20
topic.model <- MalletLDA(num.topics=n.topics, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(mallet.instances)
topic.model$setAlphaOptimization(20, 50)
topic.model$train(500)
topic.model$maximize(10)
books <- books %>% slice(1:250)
mallet.instances <- mallet.import(id.array = as.character(books$title),
text.array = as.character(books$text),
stoplist.file = "data/stopwords.txt")
n.topics <- 20
topic.model <- MalletLDA(num.topics=n.topics, alpha.sum = 1, beta = 0.1)
topic.model$loadDocuments(mallet.instances)
topic.model$setAlphaOptimization(20, 50)
topic.model$train(500)
topic.model$maximize(10)
write.csv(books, file = "data/scifi.csv")
View(gatherWords)
books <- slice(books, 1:200)
View(books)
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " ")) %>%
mutate(characters = nchar(text)) %>%
arrange(desc(characters)) %>%
ungroup() %>%
slice(1:150) %>%
select(text, title, author)
View(books)
write.csv(books, file = "data/scifi.csv")
books <- fread("https://raw.githubusercontent.com/rccordell/s18tot/gh-pages/labs/data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
select(text, title, author)
library(tidytext)
library(tidyverse)
library(gutenbergr)
library(tokenizers)
library(rtweet)
library(birdnik)
vignette(tokens)
vignette(token)
twitter_token <- create_token(
app = "Rav_Bot",
consumer_key = "4bOSrI16hLUcO17CT6zjGJrMF",
consumer_secret = "M5wyn3oG4vf9ebwuET9Dtv4pPwPLKgs5ftQTpPz25Mx8OUGsI8")
woeid <- "2367105"
trend <- getTrends(woeid)[,1] %>%
as_data_frame() %>%
rename(trend = value) %>%
filter(grepl("^#", trend))
twitter_token <- create_token(
app = "Rav_Bot",
consumer_key = "4bOSrI16hLUcO17CT6zjGJrMF",
consumer_secret = "M5wyn3oG4vf9ebwuET9Dtv4pPwPLKgs5ftQTpPz25Mx8OUGsI8")
woeid <- "2367105"
trend <- get_trends(woeid)[,1] %>%
as_data_frame() %>%
rename(trend = value) %>%
filter(grepl("^#", trend))
trend <- get_trends(woeid)[,1] %>%
as_data_frame() # %>%
View(trend)
trend <- get_trends(woeid)[,1] %>%
as_data_frame() %>%
filter(grepl("^#", trend))
View(trend)
poem <- paste(c("Leave my ", poem_word("noun"), " unbroken!—quit the ", poem_word("noun"), " above my ", poem_word("noun"), "!\n", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', trend %>% sample_n(1), "!'"), collapse = "")
my_wordnik_key <- "d69c4ab1b7ce38d81d212b4f9990b90f6a60894c3b21f2ce8"
#the line below will set the "default" part of speech for your calls to Wordnik, but you will be able to override this setting in later code.
wordnik_pos = "adjective"
#
random_word <- function(key=my_wordnik_key,
pos=wordnik_pos, min_count=100, n=1,
min_length = 5, max_length = 10){
param <- paste0("words.json/randomWords?hasDictionaryDef=true",
"&minCorpusCount=",min_count,
"&minLength=",min_length,
"&maxLength=",max_length,
"&limit=",n,
"&includePartOfSpeech=",pos)
raw = birdnik:::query(key = key,params = param)
do.call(rbind,lapply(raw,as.data.frame))
}
random_word(pos="verb",n=5, min_count=1000)
random_word(pos="interjection",n=10, min_count=100)
poem_word <- function(x) {
random_word(pos=x,n=1,min_count=1000)[,2] %>%
as.character()
}
poem_word("interjection")
poem <- paste(c("Leave my ", poem_word("noun"), " unbroken!—quit the ", poem_word("noun"), " above my ", poem_word("noun"), "!\n", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my ", poem_word("noun"), ", and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', trend %>% sample_n(1), "!'"), collapse = "")
cat(poem)
poem <- paste(c("Leave my ", poem_word("noun"), " unbroken!—quit the ", poem_word("noun"), " above my ", poem_word("noun"), "!\n", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my heart, and", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', trend %>% sample_n(1), "!'"), collapse = "")
cat(poem)
poem <- paste(c("Leave my ", poem_word("noun"), " unbroken!—quit the ", poem_word("noun"), " above my ", poem_word("noun"), "!\n", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition")," my heart, and ", poem_word("verb"), " thy ", poem_word("noun"), " from ", poem_word("preposition"), " my ", poem_word("noun"), '!" \nQuoth the Ravbot, "Never ', trend %>% sample_n(1), "!'"), collapse = "")
cat(poem)
if(nchar(poem) < 280) {
post_tweet(poem)
} else {
print("The poem is too long. Please rerun the generator and try again!")
}
library(tidyverse)
library(tidytext)
library(gutenbergr)
library(stringr)
library(data.table)
library(mallet)
library(tidyverse)
library(tidytext)
library(gutenbergr)
library(stringr)
library(data.table)
library(mallet)
books <- fread("data/scifi.csv", stringsAsFactors=FALSE, encoding="Latin-1") %>%
select(text, title, author)
View(books)
books_words <- books %>%
unnest_tokens(word, text)
View(books_words)
View(books_words)
